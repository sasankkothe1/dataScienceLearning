{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science project basics\n",
    "\n",
    "> This is my first data science project ever developed. With this, an attempt was made to learn about the data science.\n",
    "> This project contains various data science methods like data extraction, data cleaning, graphs and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration;\n",
    "\n",
    "Below code is used to explore the data from the data sets.\n",
    "* There are two datasets. \n",
    "    * Google play store dataset.\n",
    "    * Apple store dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "### opening playstore data set\n",
    "playStore_file = open('googleplaystore.csv')\n",
    "read_playStore_file = reader(playStore_file)\n",
    "playStore = list(read_playStore_file)\n",
    "\n",
    "playStore_header = playStore[0]\n",
    "playStore = playStore[1:]\n",
    "\n",
    "### opening applestore data set\n",
    "appleStore_file = open('applestore.csv')\n",
    "read_appleStore_file = reader(appleStore_file)\n",
    "appleStore = list(read_appleStore_file)\n",
    "\n",
    "appleStore_header = appleStore[0]\n",
    "appleStore = appleStore[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "Here we write a function, __explore_data__ which takes following arguments:\n",
    "* __dataset__ : This contains the dataset as input that is extracted from the above step.\n",
    "* __start__ : Start point of the slice.\n",
    "* __end__ : End point of the slice.\n",
    "* __rows_and_colums = False__: This is by default false. If set true then number of rows and columns of the dataset are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns = False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "    if rows_and_columns:\n",
    "        print(\"Number of rows in the dataset: \", len(dataset))\n",
    "        print(\"Number of columns in the dataset: \", len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "['Pixel Draw - Number Art Coloring Book', 'ART_AND_DESIGN', '4.3', '967', '2.8M', '100,000+', 'Free', '0', 'Everyone', 'Art & Design;Creativity', 'June 20, 2018', '1.1', '4.4 and up']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore_data(playStore, 1, 5, rows_and_columns = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "['529479190', 'Clash of Clans', '116476928', 'USD', '0.0', '2130805', '579', '4.5', '4.5', '9.24.12', '9+', 'Games', '38', '5', '18', '1']\n",
      "\n",
      "\n",
      "Number of rows in the dataset:  7197\n",
      "Number of columns in the dataset:  16\n"
     ]
    }
   ],
   "source": [
    "explore_data(appleStore, 1, 3, rows_and_columns = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Now we shall clean the data. __Data Cleaning__ is the step where data is cleaned inorder to get the accurate results. In this cleaning data phase, following steps are done:\n",
    "* Inaccurate data is detected. We either correct it or remove it.\n",
    "* Duplicate data is detected. These are removed.\n",
    "\n",
    "In the below step, we delete the row with missing data. In our case, record 10472 has a wrong entry. So we delete that row. __(Make sure the we execute the del statement only once.)__ This deletion step is in __ln[6]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "print(playStore_header)\n",
    "print('\\n')\n",
    "print(playStore[1])\n",
    "print('\\n')\n",
    "print(playStore[10472])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "#del(playStore[10472])\n",
    "print(playStore[10472])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above piece of code, we removed the wrong data entry. Now let us try removing the duplicate values.\n",
    "Here in this example, we are trying to remove the duplicate value __name = Instagram__ from the googleplaystore dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577446', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66509917', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n"
     ]
    }
   ],
   "source": [
    "for app in playStore:\n",
    "    name = app[0]\n",
    "    if name == \"Instagram\":\n",
    "        print(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding duplicate entries in the data\n",
    "So if observed, there are 4 duplicate __Instagram__ apps. And also it is said in the problem statement [here](https://github.com/dataquestio/solutions/blob/master/Mission350Solutions.ipynb) (see below line 6), there are in total 1181 duplicate apps in the __playStore dataset.__ \n",
    "in the below step, let us separate duplicate apps from the unique apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of duplicate apps:  1181\n",
      "Total number of unique apps:  9660\n"
     ]
    }
   ],
   "source": [
    "unique_apps = []\n",
    "duplicate_apps = []\n",
    "\n",
    "for app in playStore:\n",
    "    name = app[0]\n",
    "    if name in unique_apps:\n",
    "        duplicate_apps.append(app[0])\n",
    "    else:\n",
    "        unique_apps.append(app[0])\n",
    "        \n",
    "print(\"Total number of duplicate apps: \", len(duplicate_apps))\n",
    "print(\"Total number of unique apps: \",len(unique_apps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, there are 1181 duplicate apps in the playstore. Hence the next step would be the removal of duplicate entries.\n",
    "\n",
    "### Removing duplicate entries\n",
    "In order to get the accurate analysis of the data, we shall have to remove all the duplicate entries from the dataset.\n",
    "But rather than removing the duplicate entries randomly, there is a better way to remove them.\n",
    "\n",
    "If we observe the results of the duplicate app __Instagram__, the main difference occurs in the 4th position of the entry, that corresponds to the rating os the application. This states that the ratings of the app were collected at different times. Hence the better way of removing this entry is to keep that entry whose rating is highest and discard the remaining values. This way, we get more accurate results. Let's do this as the below steps:\n",
    "* Create a dictionary where each key is a unique app name, and the value is the highest number of reviews of that app\n",
    "* Use the dictionary to create a new data set, which will have only one entry per app (and we only select the apps with the highest number of reviews)\n",
    "\n",
    "Let's start creating the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "\n",
    "\n",
    "for app in playStore:\n",
    "    name = app[0]\n",
    "    n_reviews = app[3]\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "        \n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence in the above code, we did create a dictionary that holds the data excluding the duplicate entries from the dataset. \n",
    "So it is clear that the number of duplicate entries in the data set is 1181. So the difference obtained after removing the duplicate apps from all the apps present in the playStore data set should be equal to the length of the dictionary. Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected length:  9660\n",
      "Actual length:  9660\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected length: \", len(playStore) - 1181)\n",
    "print(\"Actual length: \", len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us use the dictionary to remove the duplicate values from the dataset __playStore__. We will obtained a __clean dataset__ after performing this activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_playStore = []\n",
    "already_added = []\n",
    "\n",
    "for app in playStore:\n",
    "    name = app[0]\n",
    "    reviews = app[3]\n",
    "    \n",
    "    if (reviews_max[name] == reviews) and (name not in already_added):\n",
    "        clean_playStore.append(app)\n",
    "        already_added.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "['Pixel Draw - Number Art Coloring Book', 'ART_AND_DESIGN', '4.3', '967', '2.8M', '100,000+', 'Free', '0', 'Everyone', 'Art & Design;Creativity', 'June 20, 2018', '1.1', '4.4 and up']\n",
      "\n",
      "\n",
      "Number of rows in the dataset:  9660\n",
      "Number of columns in the dataset:  13\n"
     ]
    }
   ],
   "source": [
    "explore_data(clean_playStore, 0, 4, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above steps, we have successfully removed the duplicate apps from the dataset using dictionary and created a clean data set called __clean_playStore__.\n",
    "\n",
    "The main motto of the project is to analyse the __English app sales in both playStore and appleStore.__ So now it is time to remove non english apps from the clean data set.\n",
    "\n",
    "### Removing non-english apps from the dataset.\n",
    "There are many non-english apps in the clean dataset we obtained from the above step. This can be done using python's inbuilt function called __ord()__. This function returns the unicode of a symbol in python. All the unicodes above 127 are special characters that state non-english letters. Further more information can be found [here](https://en.wikipedia.org/wiki/List_of_Unicode_characters)\n",
    "\n",
    "It is given that entries 4415 and 7940 in clean_playStore datasets are non-English apps as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国語 AQリスニング\n",
      "لعبة تقدر تربح DZ\n"
     ]
    }
   ],
   "source": [
    "print(clean_playStore[4415][0])\n",
    "print(clean_playStore[7941][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 (Removing non-english apps using ord())\n",
    "We are not interested in the apps like above. So let us create a function to identify non-english strings as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(string):\n",
    "    \n",
    "    for character in string:\n",
    "        if(ord(character) > 127):\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test the above function with non-english apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(is_english(\"Instagram\"))\n",
    "print(is_english(\"中国語 AQリスニング\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
